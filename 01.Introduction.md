# Containerization With Docker

## Virtual Machine
It is a software-based emulation of a physical computer. It runs an operating system (OS) and applications just like a real computer, but instead of running directly on hardware, it operates inside a virtualized environment managed by a hypervisor.

* Hypervisor creates and manages VMs.
* Each VM gets cirtual CPU, RAM, storage, and network resources.
* Multiple VMs can run on the same physical hardware, sharing the resources remaining isolated.

### What is Hypervisor
* It is a software that provides hardware-level virtualization.
* Compute, Network, and Storage are the three pillars when considering virtualization.

```mermaid
graph TB
    A[Compute] -->|Processes Workloads| B[Virtual Machines / Containers]
    C[Network] -->|Manages Connectivity| D[Virtual Networks / Load Balancers]
    E[Storage] -->|Stores Data| F[Databases / Blob Storage]
    
    subgraph Virtualization
        A
        C
        E
    end
```

### Types of Virtualization
- Hardware-Level Virtualization. (Uses Hypervisor to create VMs)
- OS-Level Virtualization.(Uses containers)

## Container Evolution
```mermaid
graph TD
    A[Hardware] --> B[Operating System]
    B --> C[App] 
    B --> D[App] 
    B --> E[App] 
    subgraph Traditional Deployment
        C
        D
        E
    end

    A1[Hardware] --> B1[Operating System]
    B1 --> C1[Hypervisor]
    C1 --> D1[Virtual Machine 1]
    C1 --> E1[Virtual Machine 2]
    D1 --> F1[Operating System]
    E1 --> G1[Operating System]
    F1 --> H1[Bin/Library + App]
    G1 --> I1[Bin/Library + App]
    subgraph Virtualized Deployment
        D1
        E1
    end

    A2[Hardware] --> B2[Operating System]
    B2 --> C2[Container Runtime]
    C2 --> D2[Container 1]
    C2 --> E2[Container 2]
    D2 --> F2[Bin/Library + App]
    E2 --> G2[Bin/Library + App]
    subgraph Container Deployment
        D2
        E2
    end
```



## What is Docker
It is an open-source containerization platform designed to simplify the development, deployment, and management of applications.
It helps us to manage application infrastructure using various concepts such as images, containers, Swarms, and Microservices.

## Docker Components
1. **Docker Engine**: It is the core software that enables containerization.It allows us to build , run, and manage containers on a host system.
2. **Images and containers**: Docker images are the read-only templates containing the application code and environment, while containers are runtime instances of these images that execute in isolated environments.
3. **Storage and volumes**: Docker storage manages data peristence for containers.
Volumes store data outside the container's filesystem, ensuring it persists across restarts and re-creations.
4. **Compose and Hub** Docker Compose is a tool for defining and managing multi-container docker applications.Docker Hub is a cloud based registry service for storing, sharing, and distributing Docker images.
5. **Network and registry**: Docker networks enable secure, isolated communication between containers.Docker registries, like Docker Hub or private registries, store and distribute Docker images.

## Why use Docker
- **Consistency Across Environments**: It ensures that application works seamlessly in any environment from development through staging to production.
- **Rapid Deployment**: Containers can be spun up in seconds much faster than deploying applications on physical or virtual machines.
- **Microservices Architecture**: It suits microservices architectures by allowing each component to run in seperate container with all dependencies.
- **Scalability**: Containers can be easily started, stopped or replicated across hosts to scale out or handle increased load.

## Docker Architecture
Docker is build on a client-server model consisting of three main components: Docker Client, Host, and Registry.

### Docker Client
- The Docker client allows users to interact with Docker through commands like `docker run, docker build, and docker pull`.These commands are sent to the Docker daemon for execution.

### Docker Host
- Consists of Docker daemon that manages Docker objects like images and containers.
- Images are read only templates containing all dependencies.
- Containers are run-time instances of the docker image.

### Docker Registry
- Images in the registry are stored in repositories in the registry.
- `docker pull` command is used to fetch the images from the registry.
- Extensions and Plugins extend Docker's functionality, allowing integration with various tools and platforms.

### Workflow
- `docker build` : The client sends a build command to the Docker daemon,  which constructs an image based on the instructions in a Dockerfile and stores it on the Docker host.
- `docker pull` : The client requests an image from the registry.The daemon retrieves the image and stores it locally.
- `docker run` : The client instructs the daemon to run a container from an image.The daemon creates and starts the container, using the specified image.

### Components of Docker Architecture
- **Docker Client** : This is the interface through which users interact with Docker.It sends requests to the Docker daemon
- **Docker Daemon** : The daemon is responsible for building, running, and distributing Docker containers.
- **Docker Host** : It is the machine (Physical or Virtual) running the Docker daemon.
- **Docker Registry** : It holds different versions of images and facilitates image sharing across different environments.
- **Images** : These are the independent packages that contain all the essentials for running software.
- **Containers** : They functions independently, leveraging the host machhine's OS kernel, with distinct file systems.
- **Networks** : Docker allows creating isolated networks to connect containers and control their communication.
- **Storage** : Docker offers storage choices, such as volumes and bind mounts, to store data produced by containers. 

```mermaid
graph TD;
    A[Docker Client] -->|Sends commands| B[Docker Daemon];
    B -->|Manages| C[Docker Objects];
    C -->|Includes| D[Images];
    C -->|Includes| E[Containers];
    C -->|Includes| F[Networks];
    C -->|Includes| G[Storage];

    B -->|Pulls & Pushes| H[Docker Registry];
    H -->|Stores| D;
    
    A -->|Builds Images| D;
    A -->|Runs Containers| E;
    
    subgraph Docker Host
        B
        C
    end

    subgraph Registry
        H
    end
```

## Docker Engine
- It is the fundamental component of the Docker platform that provides the core containerization technology for building, containerizing  and running appications.
- It works like a package manager and operates internally to facilitate the necessary components for Docker Daemon to work on Host.
## Namespaces & CGroups
### Namespaces
- Namespaces provide a layer of isolation for containers.		
- Each aspect of a container runs in a separate namespace and its access is limited to that namespace.				
- When you run a container, Docker creates a set of namespaces for that container.
- Namespace makes processes running inside that namespace believe they have their own instance of that resource.		
- A namespace can limit visibility to certain process trees, network interfaces, user IDs, or filesystem mounts.
### CGroups

- A control group (cgroup) is a Linux kernel feature that limits an application to a specific set of resource usage (CPU, memory, disk I/O, network, and so on)
- Control groups allow Docker Engine to share hardware resources to containers and optionally enforce limits and constraints.
- For example, you can limit the memory available to a specific container. 
- Cgroups involve resource metering and limiting: Memory, CPU, Storage I/O, Network 		

```mermaid
graph TD;
    A[Docker Container] -->|Isolated by| B[Namespaces];
    A -->|Controlled by| C[CGroups];

    subgraph "Namespaces (Isolation)"
        B1[Process Isolation]
        B2[Network Isolation]
        B3[User ID Isolation]
        B4[Filesystem Isolation]
        B5[Mount Isolation]
        B -->|Includes| B1;
        B -->|Includes| B2;
        B -->|Includes| B3;
        B -->|Includes| B4;
        B -->|Includes| B5;
    end

    subgraph "CGroups (Resource Management)"
        C1[Memory Limits]
        C2[CPU Constraints]
        C3[Storage I/O Control]
        C4[Network Bandwidth Limits]
        C -->|Manages| C1;
        C -->|Manages| C2;
        C -->|Manages| C3;
        C -->|Manages| C4;
    end
```

## Docker Commands
```bash
$ docker --version ## to check docker version
$ docker image ls ## to list the docker images
$ docker images ## to list the docker images
$ docker image pull jenkins ## to pull images from the hub
```
- `docker run` consists of three operations
  - docker pull
  - docker container create
  - docker container start

### Example of docker run command with details
- `docker run -dt --name nginx-lb -p 8081:80 ngnix` 
  - `docker run` command to start new container
  - `-d` runs container in detached mode (background)
  - `-t`  allocates a pseudo-TTY, which is helpful for interactive processes (although not strictly necessary for a simple nginx container in detached mode, it is a good practice).
  - `--name nginx-lb` assigns the name nginx-lb to the container.This should be unique.
  - `-p 8081:80` publishes port 80 of the container to port 8081 of the host machine, if you access http://localhost:8081 in your browser, you will be directed to the nginx web server running in the container
  - `nginx` specifies the docker image to use.
- Check if the container is running `docker ps`
- To getting inside the `docker exec -it nginx-lb /bin/sh`
- To see logs `docker logs nginx-lb`
- Stop the container using the command `docker stop nginx-lb`
- Remove the container `docker rm ngnix-lb`
- Remove the image `docker rmi nginx`

### Example of Creating the Docker Image
```bash
$ mkdir node-docker
$ cd node-docker
## Create sample app.js file here
```
```js
// app.js
const http = require('http');

const hostname = '0.0.0.0';
const port = 80;

const server = http.createServer((req, res) => {
    res.statusCode = 200;
      res.setHeader('Content-Type', 'text/plain');
        res.end('Hello Docker Chief\n');
});

server.listen(port, hostname, () => {
    console.log('Server running at http://%s:%s/', hostname, port);
});

process.on('SIGINT', function() {
    console.log('Caught interrupt signal and will exit');
    process.exit();
});
```
```bash
// Create a file named Dockerfile here
```
```Dockerfile
# Use an official Node runtime as the parent image
FROM node:6

# Set the working directory in the container to /app
WORKDIR /app

# Copy the current directory contents into the container at /app
ADD . /app

# Make the container's port 80 available to the outside world
EXPOSE 80

# Run app.js using node when the container launches
CMD ["node", "app.js"]
```
```bash
# Create a Container Image
$ docker build -t node-app:0.1 -f ./Dockerfile .
# Check to see image is created
$ docker images
# Create the container with the image created
$ docker run --name node-app -dt -p 82:80 node-app:0.1
# Check the container is running or not
$ docker ps
$ docker logs node-app
```
